{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a4ecc2",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "    <h1> Tutorial 5 Part 2 </h1> \n",
    "    <h2> Introduction to Generative Adversarial Networks </h2>\n",
    "</div>      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44349bb9",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This Jupyter notebook will walk you through building a simple GAN model and training it on the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) using [PyTorch](https://pytorch.org/). PyTorch is a very powerful library written in Python and C++ that facilitates the building and training of neural networks.\n",
    "\n",
    "This tutorial is in 2 parts this is **Part 2**.\n",
    "\n",
    "**Part 1** was adapted from Caitlin Howarth's Presentation and tutorial as part of the LIFD Work shop series. Some of the code and explanations from this tutorial came from [Aleksa Gordić's pyctorch-gans repository](https://github.com/gordicaleksa/pytorch-gans). It contains some more in-depth explanations, as well as examples of more advanced GAN models than we covered here.\n",
    "\n",
    "**Part 2** is an applied Earth Science example based on a [Met Office](https://www.metoffice.gov.uk/) example tropical cyclone example using [Unified Model](https://www.metoffice.gov.uk/research/approach/modelling-systems/unified-model/index) output [1]. The code and scripts used are taken from the [MetOffice/ML-TC](https://github.com/MetOffice/ML-TC) repository. GANs are allready being applied to Earth Science applications such as [improving precipitation nowcasting](https://www.nature.com/articles/s41586-021-03854-z), this example will use similar prinicals to explore tropical cyclones.  \n",
    "\n",
    "\n",
    "**PART 2 uses a much larger dataset (10GB) that can not be run on BINDER or GOOGLE CO-LAB, Gerating the dataset will take up to 2 hours on a resonably powerful machine and training the dataset will take up to X hours with GPUS**\n",
    "\n",
    "**Petrained models have been saved for both tutorial parts so if you do not have GPUs available then you can still run the turorial in a reasonable timeframe**\n",
    "\n",
    "\n",
    "## The very basics\n",
    "\n",
    "If you know nothing about neural networks there is a [toy neural network python code example](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/tree/main/ToyNeuralNetwork) included in the [LIFD ENV ML Notebooks Repository]( https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS). Creating a 2 layer neural network to illustrate the fundamentals of how Neural Networks work and the equivlent code using the python machine learning library [keras](https://keras.io/). \n",
    "\n",
    "## Recommended reading \n",
    "\n",
    "\n",
    "* [Introduction to Neural Networks]()\n",
    "* [Introduction to Generative Adversarial Newtworks](https://towardsdatascience.com/fundamentals-of-generative-adversarial-networks-b7ca8c34f0bc)\n",
    "* [Auto Encoders](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798)\n",
    "* [Neural Networks for Regression Problems](https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33)\n",
    "* [Digitizing Sketches of the Earth’s Surface with the AI Behind Deep Fakes (IBM Earth Science Example](https://www.ibm.com/blogs/research/2019/06/good-gans/)\n",
    "* [DCGAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "* [1] *Steptoe, H., Savage, N.H., Sadri, S. et al. Tropical cyclone simulations over Bangladesh at convection permitting 4.4 km & 1.5 km resolution. Sci Data 8, 62 (2021). [https://doi.org/10.1038/s41597-021-00847-5](https://doi.org/10.1038/s41597-021-00847-5)*\n",
    "* [2] *Ravuri, S., Lenc, K., Willson, M. et al. Skilful precipitation nowcasting using deep generative models of radar. Nature 597, 672–677 (2021). [https://doi.org/10.1038/s41586-021-03854-z](https://doi.org/10.1038/s41586-021-03854-z)* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7dbc45",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "The below cell calls a python script that will download all the necessary [UM]() data and make set of netcdf files containing variables for 11 cyclones: \n",
    "    \n",
    "**BOB01**, **BOB07**, **TC01B**, **AKASH**, **SIDR**, **RASHMI**, **AILA**, **VIYARU**, **ROANU**, **MORA** and **FANI**   \n",
    "\n",
    "    \n",
    "* **fg** - wind_speed_of_gust\n",
    "* **hur** - relative_humidity\n",
    "* **psl** - air_pressure_at_sea_level\n",
    "* **rsds** - surface_downwelling_shortwave_flux_in_air\n",
    "* **rsnds** - net_down_surface_sw_flux_corrected\n",
    "* **tas** - air_temperature\n",
    "* **ua** - x_wind\n",
    "* **va** - y_wind\n",
    "* **wbpt** - wet_bulb_potential_temperature\n",
    "* **zg** - geopotential_height    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "cd ML-TC/01-basic-GAN/\n",
    "./getbengaldata.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b666510",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "    \n",
    "<h1> Machine Learning Theory </h1>\n",
    " \n",
    "Generative Adversarial Newtworks are a pair of Neural Networks that work to generate rather than predict. The example you've probably see in [mainstream media](https://www.artificialintelligence-news.com/2022/05/09/kendrick-lamar-uses-deepfakes-in-latest-music-video/) is deepfakes, where the network has been trained to produce images of humans that are so good even humans can't tell the difference  \n",
    "    \n",
    "Generative Adversarial Newtworks are made up of two [Neural Networks](): a generator and a discriminator. Both networks are equally bad at their respective tasks initially. As training continues, both networks compete with one another to get better at their respective tasks. Eventually, the generator becomes so good that humans can’t tell the difference (hopefully!)\n",
    "    \n",
    "**The Generator**\n",
    "\n",
    "<a href=\"\">\n",
    "<img src=\"figs/generator.png\">\n",
    "</a>\n",
    "\n",
    "The generator takes a latent code as an input, and then decodes that vector into an output.\n",
    "\n",
    "Different latent codes should result in different outputs.\n",
    "\n",
    "In the original implementation of GANs, the generator never actually sees the training dataset, and is solely guided by the discriminator. \n",
    "\n",
    "    \n",
    "**The Discriminator**    \n",
    "<a href=\"\">\n",
    "<img src=\"figs/discriminator.png\">\n",
    "</a>\n",
    "\n",
    "    \n",
    "The discriminator is just a simple regression network and outputs a score from 0 (fake) to 1 (real).\n",
    "\n",
    "Values closer to 0 or 1 represent increased certainty that a sample is fake or real respectively.\n",
    "    \n",
    "**Loss Functions**\n",
    "\n",
    "Adversarial loss is essentially a minimax game, as proposed by Ian Goodfellow et al. [1]\n",
    "\n",
    "The discriminator attempts to maximise the likelihood of correctly predicting real samples as real, and fake samples as fake.\n",
    "\n",
    "The generator attempts to maximise the likelihood of the discriminator predicting that the fake samples it generates are real.\n",
    "\n",
    "* The discriminator loss is defined as: , where  is the discriminator,  is the generator,  is a sample from the real distribution and  is a latent vector given to the generator.\n",
    "\n",
    "* The generator loss is defined as: , where  is the discriminator,  is the generator, and  is a latent vector given to the generator.\n",
    "    \n",
    "References:\n",
    "    \n",
    "* [1] Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y. 2014. Generative Adversarial Networks. [arXiv:1406.2661](https://arxiv.org/abs/1406.2661)  [cs, stat].\n",
    "\n",
    "</div>    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f630c7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "<h1> Python </h1>\n",
    "\n",
    "Basic python knowledge is assumed for this tutorial. For this tutorial the main machine learning library we'll be working [PyTorch](https://pytorch.org/). Python specific information will be colour coded blue.\n",
    " \n",
    "    \n",
    "## PyTorch\n",
    "    \n",
    "[PyTorch](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e) is an open source deep learning framework Pytorch is very *pythonic*, so if you are used to coding in python using PyTorch should come naturally. \n",
    "\n",
    "    \n",
    "References:\n",
    "    \n",
    "* [https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e)\n",
    "*    \n",
    "    \n",
    "</div>\n",
    "    \n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3a558",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffffcc; padding: 10px;\">\n",
    "    \n",
    "<h1> Requirements </h1>\n",
    "\n",
    "These notebooks should run \n",
    "\n",
    "<h2> Python Packages: </h2>\n",
    "\n",
    "* Python 3\n",
    "* PyTorch\n",
    "* time\n",
    "* os\n",
    "* numpy\n",
    "* matplotlib=3.0 \n",
    "\n",
    "\n",
    "<h2> Data Requirements</h2>\n",
    "\n",
    "This notebook referes to some data included in the git hub repositroy\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be30e5",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "\n",
    "1. [Download MNIST Dataset](#Download-MNIST-Dataset)\n",
    "2. [Building the GAN](#Building-the-GAN)\n",
    "3. [Preparing to train](#Preparing-to-train)\n",
    "4. [Training](#Training)\n",
    "5. [Evaluating the GAN](#Evaluating-the-GAN)\n",
    "6. [Example Application to Earth Sciences](Example-Application-to-Earth-Sciences) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688b914",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "**Import python modules**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04606aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "875cb76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d2b24",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "Check if GPU's available. This code will run on standard CPU's too just a lots slower.\n",
    "    \n",
    "If no GPU's are detected, then pretrained model weights will be used set by the flag\n",
    "    \n",
    "```python\n",
    "train_local=False\n",
    "```\n",
    "\n",
    "**If you get a message saying no GPU available but you think there should be this means you have not managed to compile a GPU version of PyTorch and need to follow the instructions in [PyTorchCondaRecipe.md](PyTorchCondaRecipe.md)**    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dddde8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro P1000\n",
      "GPUs found Setting train_local to True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  train_local=True\n",
    "  GPUs=True  \n",
    "  print(torch.cuda.get_device_name(device))\n",
    "  print('GPUs found Setting train_local to True')\n",
    "else:\n",
    "  train_local=False\n",
    "  GPUs=False\n",
    "  print(\"WARNING: No GPU available. Setting train_local to False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0a31c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "If you want to override this behaviour and train your own network if you don't mind waiting or if you have GPUS available but don't want to wait 20 mins training your own network later you can the the next cell to:\n",
    "\n",
    "```python\n",
    "override_train_local=True\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf422c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set as override_train_local=False to maintain default behaviour for your hardware\n",
    "override_train_local=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4514336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default behaviour\n"
     ]
    }
   ],
   "source": [
    "if override_train_local :\n",
    "    if GPUs:\n",
    "        train_local=False  \n",
    "        print('WARNING SETTING TRAIN LOCAL TO FALSE, PRETRAINED MODEL WILL BE USED')\n",
    "    else:\n",
    "        train_local=True\n",
    "        print('WARNING SETTING TRAIN LOCAL TO TRUE, WILL TRAIN MODEL OVER A LONG TIME ON CPUS')\n",
    "else: \n",
    "    print('Default behaviour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41052f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 0\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b02e6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path='.'\n",
    "data_path='ML-TC/01-basic-GAN/Data/'\n",
    "num=0\n",
    "for dir in [name for name in os.listdir(base_path)]:\n",
    "    # print(dir)\n",
    "    if dir.isnumeric():\n",
    "        num=max(num,int(dir))\n",
    "save_path=str(num+1)+\"/\"\n",
    "os.mkdir(save_path)\n",
    "sys.stdout = open(save_path+'output.txt', 'w+')\n",
    "print(save_path)\n",
    "t = open(save_path+\"text.txt\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85038c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c25a0934",
   "metadata": {},
   "outputs": [],
   "source": [
    " t.write(\"Run starting\")\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 357\n",
    "# manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "t.write(\"Random Seed: \"+str(manualSeed))\n",
    "t.close()\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "# path=str(pathlib.Path(__file__).parent)+\"/Data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a712ccb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bd6d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for f in os.listdir(data_path):\n",
    "    print(f)\n",
    "    if f.endswith(\".npz\") and 'A' in f:\n",
    "        t = open(save_path+\"text.txt\", \"a\")\n",
    "        t.write(f)\n",
    "        t.close()\n",
    "        datapoint=np.load(data_path+f, allow_pickle=True)\n",
    "        for x in datapoint['arr_0']:\n",
    "            # print(len(data))\n",
    "            # print(x.shape)\n",
    "            s=x.shape\n",
    "            if s.count(s[0]) == len(s) and np.count_nonzero(~np.isnan(x)) > 3000:\n",
    "                # print(x.shape)\n",
    "                data.append(torch.from_numpy(np.nan_to_num(x)))\n",
    "# print(len(data))\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "efe8bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data:\n",
    "    plt.imshow(x, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1e914",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "PyTorch uses a DataLoader wrapper around a dataset in order to iterate through the dataset. It's where we specify the number of samples per batch, as well as whether to shuffle the data. drop_last ensures that any batch that isn't at least 128 samples gets dropped.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=workers)\n",
    "\n",
    "# # Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e59092",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.stack(data)\n",
    "# print(data.max())\n",
    "# print(data.min())\n",
    "data=data/(data.max()/2)-1\n",
    "# print(data.max())\n",
    "# print(data.min())\n",
    "# transform=transforms.Compose([transforms.Resize(image_size),\n",
    "#                             transforms.CenterCrop(image_size),\n",
    "#                             transforms.ToTensor(),\n",
    "#                             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#                         ]\n",
    "dataset=TensorDataset(data)\n",
    "# # We can use an image folder dataset the way we have it setup.\n",
    "# # Create the dataset\n",
    "# dataset = dset.ImageFolder(root=dataroot,\n",
    "#                         transform=transforms.Compose([\n",
    "#                             transforms.Resize(image_size),\n",
    "#                             transforms.CenterCrop(image_size),\n",
    "#                             transforms.ToTensor(),\n",
    "#                             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#                         ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "#real_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "     print(\"g\")\n",
    "     plt.figure(figsize=(8,8))\n",
    "     plt.axis(\"off\")\n",
    "     plt.title(\"Training Images\")\n",
    "     plt.imshow(np.transpose(vutils.make_grid(batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bdba6",
   "metadata": {},
   "source": [
    "# Building the GAN\n",
    "\n",
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "Recall that the generator has a latent space from which we draw samples from by input random vectors. Let's define it as a vector with 100 elements and create a function to generate a batch of latent inputs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7db1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cfdea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "#https://discuss.pytorch.org/t/how-do-i-print-output-of-each-layer-in-sequential/5773/3\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self,f):\n",
    "        self.f = f\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.f:\n",
    "            print(x.shape)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, f=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            PrintLayer(f),\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "            PrintLayer(f)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu, f=False):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            PrintLayer(f),\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( 256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( 128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            PrintLayer(f),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( 64,nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "            PrintLayer(f)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629bdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "# Create the generator\n",
    "netG = Generator(ngpu, True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc853eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f360002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4712ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu, True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def97a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb4e17",
   "metadata": {},
   "source": [
    "# Preparing to train\n",
    "\n",
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "    \n",
    "Now we've created our generator and discriminator, we need to train them! As it stands, they've been initiated with random weights for all trainable parameters. This means that initially, both the generator and discriminator are going to be terrible at their respective tasks.\n",
    "\n",
    "By training them, both will improve, and through the adversarial nature of the loss function, one network getting stronger *should* result in the other improving too. This isn't always the case however, sometimes either the generator or discriminator will become too strong and overpower the other. This is a failure case, and the model will no longer produce anything meaningful.\n",
    "\n",
    "In the case of the generator winning, it learns a pattern that fools the discriminator while not necessarily representing the dataset at all. Often, the mode will collpase, with all latent variables converging to the same output image. If the discriminator wins, the generator loses its gradient and will begin to produce garbage outputs.\n",
    "\n",
    "We want to avoid both cases, which makes GANs more difficult to train than most other machine learning models.\n",
    "\n",
    "To begin our training, we first need to create an optimiser for each network. This optimiser implements an algorithm for performing backpropagation on the neural network. For this demo, we'll use the well known and effective Adam optimiser. If you want to know more about how this works, the paper it was proposed in can be found [here](https://arxiv.org/abs/1412.6980).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bccb6",
   "metadata": {},
   "source": [
    "# Learning Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa9700",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "\n",
    "We set the initial learning rate for both optimisers to 0.0002. The learning rate is the single most important hyperparameter when training, and changing it can have drastic results. Try experimenting with much larger learning rates on both the generator and discriminator and see how it affects training!\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "    \n",
    "**There is a link back to here at the end of this section of the tutorial.**\n",
    "    \n",
    "After you have gone through the tutorial rerun the section below with different learning rates to see the effects. \n",
    "    \n",
    "The learning rates are initally set at:\n",
    "```python\n",
    "    learning_rate_dis = 0.0002\n",
    "    learning_rate_gen = 0.0002\n",
    "```    \n",
    "    \n",
    "For example try increasing or decreasing by a factor of 10. What happens if you alter one rate but not the other?   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e808f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62145637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "# manualSeed = 999\n",
    "manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cc8c7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "    \n",
    "We need to define the loss function that we're going to use to train our networks. We'll use binary cross entropy to measure our discriminator's predictions.\n",
    "\n",
    "If we input real images into the discriminator we expect it to output 1 (100% certainty that the image is real).\n",
    "\n",
    "The further away it is from 1 and the closer it is to 0 the more we should penalize it, as it is making an incorrect prediction.\n",
    "\n",
    "BCE loss essentially becomes -log(x) when the target label is 1.\n",
    "\n",
    "Similarly for fake images, the target label is 0 (as we want the discriminator to output 0 for fake images) and we want to penalise the generator if it starts outputing values close to 1. So we basically want to mirror the above loss function and that's just: -log(1-x).\n",
    "\n",
    "BCE loss basically becomes -log(1-x) when it's target label is 0.\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20031128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c021a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "print(fixed_noise.shape)\n",
    "print(fixed_noise.max())\n",
    "print(fixed_noise.min())\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3197990",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "Finally, let's define a few variables to help our training process.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da5c84",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "We're now ready to begin our training loop!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1ac9d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b32ca2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "Let's create our GAN training loop. We start with training the discriminator, as this helps to prevent early mode collapse. \n",
    "</div>   \n",
    "\n",
    "<div style=\"background-color: #ffcdcc; padding: 10px;\">     \n",
    "\n",
    " **For 100 epochs, this training will take approximately 20-25 minutes, go grab a coffee!**\n",
    "\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e51e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device).unsqueeze(1)\n",
    "        b_size = real_cpu.size(0)\n",
    "        # print(b_size)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = torch.squeeze(netD(real_cpu))\n",
    "        # Calculate loss on all-real batch\n",
    "        # print(output)\n",
    "        # print(output.shape)\n",
    "        # print(label)\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        # print(fake.shape)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                % (epoch, num_epochs, i, len(dataloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu().numpy()\n",
    "            img_list.append(fake)\n",
    "            np.save(\"produced_small.npy\",img_list)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a14722",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "\n",
    "Now our training is finished, it's time to evaluate how it's doing!\n",
    "\n",
    "If you'd like, you can check out the image samples we saved during training. Remember we created a set of constant latent inputs, meaning each image has the same input and differs only because the generator's weights have updated.\n",
    "\n",
    "The images folder contains samples produced as training has progressed. Can you see how it's improving over time?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bda7cc",
   "metadata": {},
   "source": [
    "# Evaluating the GAN\n",
    "\n",
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "\n",
    "Now we've trained our model, we can use it to generate a new handwritten digit based on the MNIST dataset, but totally unique!\n",
    "\n",
    "To start with, we'll define a few functions for prettying up and displaying the sample images.\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cfb0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59086cd",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "\n",
    "Now we've spent all that time training the model we can save ourselves time in the future by saving the trained model\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2152a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"netG.pt\"\n",
    "torch.save(netG, PATH)\n",
    "\n",
    "PATH = \"netD.pt\"\n",
    "torch.save(netD, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830fc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "HTML(ani.to_jshtml())\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
